---
layout: post
title: "​crawl4ai使用schema教程"
date: 2025-05-26
---

步骤：
1. 安装​crawl4ai
2. 参考官方文档教程：https://docs.crawl4ai.com/core/quickstart/#5-simple-data-extraction-css-based
3. 网页上分析对应的css

完整代码案例：
```python
import asyncio
import json
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
from crawl4ai.extraction_strategy import JsonCssExtractionStrategy

async def main():
    schema = {
        "name": "Trending Repos",
        "baseSelector": "article.Box-row",
        "fields": [
            {"name": "repo_name", "selector": "h2 > a", "type": "text"},
            {"name": "repo_url", "selector": "h2 > a", "type": "attribute", "attribute": "href"},
            {"name": "description", "selector": "p", "type": "text"},
            {"name": "language", "selector": "span[itemprop='programmingLanguage']", "type": "text"},
            {"name": "stars", "selector": "a[href*='/stargazers']", "type": "text"}
        ]
    }

    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://github.com/trending",
            config=CrawlerRunConfig(
                cache_mode=CacheMode.BYPASS,
                extraction_strategy=JsonCssExtractionStrategy(schema)
            )
        )
        data = json.loads(result.extracted_content)

        # 输出为 Markdown 格式
        md_output = "# GitHub Trending Repos\n\n"
        for item in data:
            md_output += f"## [{item.get('repo_name', '').strip()}](https://github.com{item.get('repo_url', '').strip()})\n"
            md_output += f"- **Description**: {item.get('description', '').strip()}\n"
            md_output += f"- **Language**: {item.get('language', '').strip()}\n"
            md_output += f"- **Stars**: {item.get('stars', '').strip()}\n\n"

        print(md_output)

if __name__ == "__main__":
    asyncio.run(main())
```
